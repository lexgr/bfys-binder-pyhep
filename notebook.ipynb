{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/uproot-logo-300px.png\" alt=\"Uproot\" width=\"300px\" style=\"margin-bottom: -50px; margin-right: 20px\"><font size=\"5\"> is a pure-Python implementation of ROOT I/O.</font>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<img src=\"img/abstraction-layers.png\" width=\"900px\">\n",
    "\n",
    "\n",
    "# What will this tutorial use?\n",
    "\n",
    "New versions of both: <b>Uproot 4</b> and <b>Awkward 1</b>. The code is adapted from Jim Pivarski's PyHEP [talk](https://github.com/jpivarski-talks/2020-07-13-pyhep2020-tutorial).\n",
    "\n",
    "The required packages are available on PyPI (pie-pee-eye) and can be easily installed with pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot4\n",
    "import awkward1 as ak\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading files is very easy! We will look at some muon data for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = uproot4.open('data/opendata_muons.root')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you open a file, you get its root directory, which has the properties of a Python dict.\n",
    "\n",
    "You can list its keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The `;1` wasn't necesssaryâ€”it's a \"cycle number,\" which ROOT uses to distinguish objects in the same directory with the same name. If unspecified, you get the highest cycle number.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.classnames()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring a TTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = root[\"Events\"]\n",
    "tree.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are all the branches of the TTree with the type name of the branch (if Uproot can determine it) and its interpretation as an array (if possible).\n",
    "\n",
    "TTrees also have a dict-like interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.typenames()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also filter the keys on name or type, wildcards are allowed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.keys(filter_name=\"P*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.keys(filter_typename=\"float[]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turning branches into arrays\n",
    "\n",
    "If a branch has a known interpretation, you can call `array` on it to get an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree[\"Muon_pt\"].array()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing to notice: this is not a NumPy array. It's because the data have different numbers of values in each element (it's a jagged array). It's an array of arrays with possibly different lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree[\"Muon_pt\"].array()[:20].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can (in Uproot 4) _force_ it to be a NumPy array, but it isn't pretty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree[\"Muon_pt\"].array(library=\"np\")[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data type (`dtype`) of this NumPy array is `object`, meaning that each element it contains is a Python object, namely another NumPy array.\n",
    "\n",
    "The default is for all arrays to be Awkward arrays, but you can override this by specifying `library`.\n",
    "\n",
    "The difference is that Awkward arrays interpret nested lists as a second dimension, whereas NumPy object arrays do not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awkward_array = tree[\"Muon_pt\"].array(library=\"ak\")\n",
    "numpy_array = tree[\"Muon_pt\"].array(library=\"np\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the first 20 events, get the first item\n",
    "awkward_array[:20, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't work with NumPy object arrays because contents are not guaranteed to be arrays\n",
    "numpy_array[:20, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another valid library is Pandas. Pandas has its own way of describing variable length structures (`MultiIndex`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree[\"Muon_pt\"].array(library=\"pd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pluralization\n",
    "\n",
    "If you look carefully, you'll notice that there's an `array` function and an `arrays` function. The latter gets multiple arrays. In the below example we get that as NumPy arrays, however `library=\"ak\"` and `library=\"pd\"` are also valid options to get Awkward arrays and a pandas dataframe respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy arrays in a dict\n",
    "pv_numpy = tree.arrays(filter_name=\"PV_*\", library=\"np\")\n",
    "pv_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_numpy[\"PV_x\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we used `filter_name` to select branches that match a pattern. We can also request specific branches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.arrays([\"PV_x\", \"PV_y\", \"PV_z\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or do calculations. (This feature exists for TTree aliases, which can be formulas.) We can even apply cuts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.arrays(\"PV\", aliases={\"PV\": \"sqrt(PV_x**2 + PV_y**2 + PV_z**2)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.arrays(\"PV\", cut=\"sqrt(PV_x**2 + PV_y**2) < 0.1\", aliases={\"PV\": \"sqrt(PV_x**2 + PV_y**2 + PV_z**2)\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple files\n",
    "\n",
    "So far so good, but this was just one small file. Taking a look at `/data/bfys`:\n",
    "\n",
    "<img src=\"img/data_bfys.png\" width=\"200px\">\n",
    "\n",
    "What if I have 100+ GBs of ROOT files that I want to open? The Nikhef laptop budget only allowed me to buy a laptop with 16GB RAM, help me!!\n",
    "\n",
    "## Concatenation\n",
    "\n",
    "The simplest way to deal with opening multiple files is to read a selection of branches entirely into memory, concatenating them. If you have enough memory, and your files are small enough, go for it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_in_memory = uproot4.concatenate(\"data/uproot-sample-*.root:sample\", [\"i4\", \"ai8\", \"Af8\", \"str\"])\n",
    "all_in_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_in_memory.i4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_in_memory.ai8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_in_memory.Af8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_in_memory.str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, often enough, you don't have enough memory. What then? \n",
    "\n",
    "## Laziness\n",
    "\n",
    "One option is to open them as lazy arrays, which opens the files (to get the number of events in each), but doesn't read the data until you use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_memory_yet = uproot4.lazy(\"data/uproot-sample-*.root:sample\")\n",
    "not_in_memory_yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"If it's not in memory, how can I see the values?\"\n",
    "\n",
    "Only the parts of the files (branches and batches of events) that are visible are read. In the above, `n` and `b` from the first file and `str` from the last file must have been read.\n",
    "\n",
    "Let's get the `Af8` field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_memory_yet.Af8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this only read from the first and last files to show the first and last values.\n",
    "\n",
    "A mathematical operation would cause them all to be read in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_memory_yet.Af8 + 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling the lazy cache\n",
    "\n",
    "After (part of) a lazy array has been read, how long does it stay in memory? Is it constantly being re-read every time we do a calculation?\n",
    "\n",
    "By default, a 100 MB cache is associated with the lazy array, but we can provide our own if we want a bigger or smaller one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = uproot4.LRUArrayCache(\"1 GB\")\n",
    "not_in_memory_yet = uproot4.lazy(\"data/uproot-sample-*.root:sample\", array_cache=cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_memory_yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_memory_yet + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's more, we can clear it when we need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration\n",
    "\n",
    "But often, that's still not enough control.\n",
    "\n",
    "We don't read arrays into memory for the fun of it, we do it to perform calculations, and lazy arrays don't control which parts of which arrays are in memory during a calculation.\n",
    "\n",
    "If you're worried about memory, the safest thing to do is to iterate over the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arrays in uproot4.iterate(\"data/uproot-sample-*.root:sample\", [\"i4\", \"Af8\"]):\n",
    "    print(arrays[\"i4\"] + arrays[\"Af8\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iteration is _not_ one event at a time. (This set of TTrees has 420 entries.) It's a _chunk of events_ at a time.\n",
    "\n",
    "In each step, a chunk of events for all specified arrays (`[\"i4\", \"Af8\"]`) is read. You do your calculation, move on to the next step, and all the previous arrays are dropped. (Only TBasket data carries over if event steps don't line up with TBasket boundariesâ€”a low-level detail.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing to ROOT files\n",
    "\n",
    "Uproot 4 cannot write to ROOT files yet: see Uproot 3 documentation.\n",
    "\n",
    "Some caveats, though:\n",
    "\n",
    "   * Writing ROOT files with Uproot will always be minimal: histograms and only basic types in TTrees.\n",
    "   * You won't be able to update an existing file, only make new files.\n",
    "   * It won't be as fast as writing with ROOT.\n",
    "\n",
    "The issues involved in _writing_ an established format are considerably different from _reading_. If anyone thinks they can do better, they're welcome to try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = uproot4.open(\"data/opendata_muons.root:Events\") # can also instantly open a tree by adding it after the filepath\n",
    "tree.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've already seen that it's \"awkward\" to deal with the jagged arrays in NumPy. However, they look and feel like records if \"zipped\" into an Awkward array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = tree.arrays(library=\"ak\", how=\"zip\")\n",
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the awkward array data type to encapsulate the structure of the events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.type(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1000000 *` means that there are a million events, `\"Muon\": var *` means that the contents of the `\"Muon\"` field are jagged: there's a variable number of them per event.\n",
    "\n",
    "We could look at a few of these as Python lists and dicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.to_list(events[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the data are not actually arranged as objects in memory; each field (`\"pt\"`, `\"eta\"`, `\"phi\"`, etc.) is in an array by itself.\n",
    "\n",
    "This means that structure-changing things like pulling out the kinematics are not expensive computations. (That is, they do not scale with the size of the dataset.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events[\"Muon\", [\"pt\", \"eta\", \"phi\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.type(events[\"Muon\", [\"pt\", \"eta\", \"phi\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events[\"Muon\", \"pz\"] = events[\"Muon\", \"pt\"] * np.sinh(events[\"Muon\", \"eta\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.type(events.Muon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.Muon.pz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since nearly all of you are familiar with NumPy, slicing arrays with boolean arrays is probably familiar to you.\n",
    "\n",
    "What's new is that the boolean arrays can now be jagged to slice jagged arrays (i.e. cut particles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.Muon.pt > 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.Muon[events.Muon.pt > 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To cut on events, we need to make the jagged array of booleans into a one-dimensional array of booleans. You can do this with a reducer (such as [ak.sum](https://awkward-array.readthedocs.io/en/latest/_auto/ak.sum.html) or [ak.max](https://awkward-array.readthedocs.io/en/latest/_auto/ak.max.html), but most likely [ak.any](https://awkward-array.readthedocs.io/en/latest/_auto/ak.any.html) and [ak.all](https://awkward-array.readthedocs.io/en/latest/_auto/ak.all.html) for booleans)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.any(events.Muon.pt > 20, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.Muon[ak.any(events.Muon.pt > 20, axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Awkward analysis\n",
    "\n",
    "Several new operations are needed when arrays can have arbitrary data structures, so the Awkward Array library is best seen as a collection of functions acting on [ak.Array](https://awkward-array.readthedocs.io/en/latest/_auto/ak.Array.html) (the array type).\n",
    "\n",
    "Probably the most important of these is [ak.num](https://awkward-array.readthedocs.io/en/latest/_auto/ak.num.html), which tells us the number of elements in each nested list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.num(events.Muon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's how many muons there are in each event.\n",
    "\n",
    "This becomes necessary if we ever try to select the first (and second, etc.) element in each event. Some events might not have any, and this will therefore yield an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.Muon[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can use [ak.num](https://awkward-array.readthedocs.io/en/latest/_auto/ak.num.html) to slice the first dimension and remove the events with 0 muons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.Muon[ak.num(events.Muon) > 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking vs cutting\n",
    "\n",
    "In the nearly two years that physicists have been doing analyses with Awkward Arrays, they've found that cuts are difficult to accumulate. If the first cut changes the length of the array from 1000000 to 969031, boolean arrays that could be applied to the first array can't be applied to the second array.\n",
    "\n",
    "In practice, they've taken a logical-and of all cuts and apply them at the end, but we can do better: we can mask, rather than cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.Muon.mask[events.Muon.pt > 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the new types that Awkward Array introduces is the \"option type,\" which allows some values to be `None`. (It's a `?` in the type specification.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making regular arrays\n",
    "\n",
    "If you're feeding your data into a machine learning pipeline, you might need the jaggedness to go away. There are functions for padding jagged arrays (with `None`) so that they reach a desired length (and replacing `None` with a preferred value): [ak.pad_none](https://awkward-array.readthedocs.io/en/latest/_auto/ak.pad_none.html) (and [ak.fill_none](https://awkward-array.readthedocs.io/en/latest/_auto/ak.fill_none.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.pad_none(events.Muon.pt, 3, clip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.fill_none(ak.pad_none(events.Muon.pt, 3, clip=True), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you're plotting something, you usually want to flatten the jaggedness. To get the muon pT distribution we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ak.flatten(events.Muon.pt), bins=120, range=(0, 60));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Awkward combinatorics\n",
    "\n",
    "We often want to find pairs of particles with some invariant mass. To do that, we need combinatoric functions like [ak.cartesian](https://awkward-array.readthedocs.io/en/latest/_auto/ak.cartesian.html) and [ak.combinations](https://awkward-array.readthedocs.io/en/latest/_auto/ak.combinations.html).\n",
    "\n",
    "<table style=\"margin-left: 0px\">\n",
    "    <tr style=\"background: white\"><td style=\"font-size: 1.75em; font-weight: bold; text-align: center\">Cartesian product (per event)</td><td style=\"font-size: 1.75em; font-weight: bold; text-align: center\">n-choose-k combinations (per event)</td></tr>\n",
    "    <tr style=\"background: white\"><td><img src=\"img/cartoon-cartesian.png\"></td><td><img src=\"img/cartoon-combinations.png\"></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muon_pairs = ak.combinations(events.Muon, 2)\n",
    "muon_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1, m2 = ak.unzip(muon_pairs)\n",
    "m1, m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masses = np.sqrt(2*m1.pt*m2.pt*(np.cosh(m1.eta - m2.eta) - np.cos(m1.phi - m2.phi)))\n",
    "masses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ak.flatten(masses), bins=80, range=(70, 110))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ak.flatten(masses), bins=240, range=(0, 12))\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms!\n",
    "\n",
    "But Lex, this is all very nice, but what about my beautiful ROOT plots? What do I do with those? Can I still use those?\n",
    "\n",
    "Excellent question!\n",
    "\n",
    "Uproot can read histograms (as well as most other ROOT objects), but it doesn't deal directly with them. The first thing that you do when extracting a histogram is to convert it to another library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms = uproot4.open(\"data/hepdata-example.root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms.classnames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms[\"hpx\"].to_boost()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a [boost-histogram](https://github.com/scikit-hep/boost-histogram), a clean design of N-dimensional histograms in the [Boost](https://www.boost.org/doc/libs/release/libs/histogram/doc/html/index.html) C++ library (with Python bindings). Boost-histogram focuses just on **filling and manipulating (e.g. slicing)** histograms.\n",
    "\n",
    "But we want to plot it, right? There's another library, [mplhep](https://github.com/scikit-hep/mplhep), which focuses just on **plotting** histograms in Matplotlib.\n",
    "\n",
    "<table style=\"margin-left: 0px\">\n",
    "    <tr style=\"background: white\">\n",
    "        <td><img src=\"img/BoostHistogramCppLogo.png\" width=\"300px\" style=\"margin-right: 20px\"></td>\n",
    "        <td><img src=\"img/BoostHistogramPythonLogo.png\" width=\"300px\" style=\"margin-right: 20px\"></td>\n",
    "        <td><img src=\"img/mplhep.png\" width=\"300px\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Now we can create a histogam in one line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "\n",
    "hep.histplot(histograms[\"hpx\"].to_boost())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mplhep\n",
    "What is this magic mplhep? mplhep is described as \"a set of helpers for matplotlib to more easily produce plots typically needed in HEP as well as style them in way that's compatible with current collaboration requirements (ROOT-like plots for CMS, ATLAS, LHCb, ALICE).\" Let's take a look!\n",
    "\n",
    "Let's start looking at some toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = np.histogram(np.random.normal(2.5, .5, 100), bins=np.arange(0,6, 0.5))\n",
    "print(\"Type:\", type(H))\n",
    "h, bins = H\n",
    "print(\"Values:\", h)\n",
    "print(\"Bins:\", bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mplhep.histplot()` for mplhep is what `plt.hist()` is for matplotlib:\n",
    "\n",
    "#### Primary goal is to stay unobtrusive\n",
    "- if you know how `plt.hist()` works, `mplhep.histplot()` should behave like you'd expect\n",
    "- painless transition back if `mpl` grows a proper histogram plotting method\n",
    "- kwargs you are used to should work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1,2, figsize=(14, 5))\n",
    "\n",
    "hep.histplot(H, ax=axs[0])\n",
    "hep.histplot(h, bins, yerr=True, ax=axs[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1,2, figsize=(14, 5))\n",
    "\n",
    "hep.histplot(H, ax=axs[0], histtype='fill', hatch='//')\n",
    "hep.histplot(H, ax=axs[1], histtype='errorbar', yerr=True, c='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should be easy to use if you're used to matplotlib!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1,3, figsize=(21, 5))\n",
    "\n",
    "hep.histplot([h, h*2], bins=bins, ax=axs[0], yerr=True, label=[\"MC1\", \"MC2\"])\n",
    "hep.histplot(np.random.poisson(h*3), bins=bins, ax=axs[1], yerr=True, label=\"Data\")\n",
    "hep.histplot([h, h*2], bins=bins, ax=axs[2], stack=True, label=[\"MC1\", \"MC2\"], density=True)\n",
    "hep.histplot(np.random.poisson(h*3), bins=bins, ax=axs[2], yerr=True, histtype='errorbar', label=\"Data\", density=True)\n",
    "for ax in axs:\n",
    "    ax.legend()\n",
    "axs[0].set_title(\"Some MCs\")\n",
    "axs[1].set_title(\"Draw Poisson Data\")\n",
    "axs[2].set_title(\"Data/MC Shape comparison\"); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's load some data and see how that works\n",
    "Maybe we can make some nice Dalitz plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dalitz data from the LHCb Starterkit\n",
    "dalitz_data = uproot4.open(\"data/dalitz2.root:tree\").arrays(library='np')\n",
    "dalitz_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the data, we have the mass squared for the comination of particles A and B and for A and C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_AB, bins = np.histogram(dalitz_data[\"M2AB\"], bins=100)\n",
    "h_AC, bins_AC = np.histogram(dalitz_data[\"M2AC\"], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1,2, figsize=(15, 7))\n",
    "hep.histplot(h_AB,bins,ax=axs[0], label=\"M2AB\")\n",
    "hep.histplot(h_AC,bins,ax=axs[1], label=\"M2AC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make a 2D plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, xedges, yedges = np.histogram2d(dalitz_data[\"M2AB\"], dalitz_data[\"M2AC\"], bins=256)\n",
    "hep.hist2dplot(H, xedges, yedges)\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default plot styles\n",
    "But this just seems like matplotlib with extra steps? Where is the HEP functionality?\n",
    "\n",
    "Well,`mplhep` comes with default plot styles! It has ATLAS, CMS, and most interestingly LHCb! It even comes with the LHCb label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(hep.style.LHCb)\n",
    "hep.histplot(h_AB,bins, label=\"M2AB\")\n",
    "plt.xlabel(\"M2AB [GeV^2]\")\n",
    "plt.ylabel(\"Entries\")\n",
    "hep.lhcb.label(data=True, paper=False, year=2020, lumi=\"420\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.lhcb.label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.hist2dplot(H, xedges, yedges)\n",
    "hep.lhcb.label() # default to 2017 simulation=True\n",
    "plt.xlabel(\"M2AB [GeV^2]\")\n",
    "plt.ylabel(\"M2AC [GeV^2]\")\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make plots look ROOT style, for the ROOT fans under us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(hep.style.ROOT)\n",
    "hep.histplot(h_AB,bins, label=\"M2AB\")\n",
    "plt.xlabel(\"M2AB [GeV]\")\n",
    "plt.ylabel(\"Entries\")\n",
    "hep.lhcb.label(data=True, paper=False, year=2020, lumi=\"420\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.hist2dplot(H, xedges, yedges)\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# boost-histogram\n",
    "\n",
    "Okay, but what if I really like ROOT histograms? NumPy and matplotlib are just now the same, I can't even fill!\n",
    "\n",
    "The Python ecosystem is missing a good Histogram object. NumPy can perform a histogram operation, but it does not produce an object, and there are limitations and performance issues. The closest thing we have to a histogram is in ROOT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the basics. We will create a histogram using boost-histogram and fill it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boost_histogram as bh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.random.normal(3.5, 2.5, size=1_000_000) # toy data with 1 million entries\n",
    "hist1 = bh.Histogram(bh.axis.Regular(40, -2, 10))  # create boost histogram object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like ROOT, we can fill _after_ we make a histogram, as many times as we want. You can fill single values, but to take advantage of the performance, you should fill with arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist1.fill(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the histogram has been filled. Let's explicitly check to see how many entries are in the histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist1.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh, that's not 1 million!! What happened to the missing items? They are in the underflow and overflow bins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist1.sum(flow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like ROOT, we have overflow bins by default. We can turn them off, but they enable some powerful things like projections.\n",
    "\n",
    "Let's plot this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(hist1.axes[0].centers, hist1.view(), width=hist1.axes[0].widths);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You can leave off the `.view()` if you want to - histograms conform to the buffer protocol. Also, you can select the axes before or after calling `.centers`; this is very useful for ND histograms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, let's be lazy, and use mplhep, which natively supports boost-histogram now. See, it all ties in together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(hep.style.ROOT)\n",
    "hep.histplot(hist1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should think of boost-histogram like NumPy: No plotting is built in, but the data is easy to access.\n",
    "\n",
    "Unlike ROOT, Histograms are built of of basic building blocks: 1 or more **axes**, and a **storage**. The storage holds **accumulators**, which can be simple doubles or ints, or more complex things that hold extra information about the operation (which might not even be a sum! (generalized histograms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration with NumPy\n",
    "\n",
    "To start using this yourself, you don't even need to change your code. Let's try the NumPy adapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins2, edges2 = bh.numpy.histogram(data1, bins=10) # using boost\n",
    "b2, e2 = np.histogram(data1, bins=10)              # using NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins2 - b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2 - edges2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! Let's start moving to the boost-histogram API, so we can use the plotting function we just learned about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist2 = bh.numpy.histogram(data1, bins=\"auto\", histogram=bh.Histogram)\n",
    "hep.histplot(hist2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can move over to boost-histogram one step at a time! Just to be complete, we can also go back to a Numpy tuple from a Histogram object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2p, e2p = bh.numpy.histogram(data1, bins=10, histogram=bh.Histogram).to_numpy()\n",
    "b2p == b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, while \"recently\" NumPy optimized 1D regular binning, it still beats optimized NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "bh.numpy.histogram(data1, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "np.histogram(data1, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple dimension\n",
    "Now we all like multiple dimension histograms, boost also has a solution for that! Let's reuse the Dalitz data for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist3 = bh.Histogram(bh.axis.Regular(256, 0, 1250,), bh.axis.Regular(256, 0., 1700))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2d = [dalitz_data['M2AB'], dalitz_data[\"M2AC\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist3.fill(*data2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(*hist3.axes.edges.T, hist3.view().T);\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is transposed because of differing indexing conventions. Let's try 3D!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3d = [np.random.normal(size=1_000_000) for _ in range(3)]\n",
    "\n",
    "hist3d = bh.Histogram(\n",
    "    bh.axis.Regular(150, -5, 5),\n",
    "    bh.axis.Regular(100, -5, 5),\n",
    "    bh.axis.Regular(100, -5, 5),\n",
    ")\n",
    "\n",
    "hist3d.fill(*data3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's project to the first two axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.hist2dplot(hist3d[:, :, sum]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boost UHI\n",
    "\n",
    "<img alt=\"Diagram of UHI\" src=\"img/boost.png\"></img> \n",
    "\n",
    "Let's explore the boost-histogram UHI syntax. With this we can easily find bin content, get slices, rebin, etc. We will start with a 1D histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = bh.Histogram(bh.axis.Regular(100, -3.5, 3.5))\n",
    "data = np.concatenate([\n",
    "    np.random.normal(-.75,.3, 1_000_000),\n",
    "    np.random.normal(.75,.3, 750_000),\n",
    "    np.random.normal(-1.5,.2, 200_000),\n",
    "])\n",
    "\n",
    "h.fill(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.histplot(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we want x from -2 to 0, in *data coordinates*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.histplot(h[bh.loc(-2):bh.loc(0)]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the contents of a bin?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h[bh.loc(-.75)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about reducing a histogram? Let's try the previous 2D Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.histplot(hist3[:, sum])\n",
    "hep.histplot(hist3[sum, :]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one part and rebin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.hist2dplot(hist3[200: 800 : bh.rebin(1), 200 :800: bh.rebin(1)]);\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many entries do we have at M2AB = 500 and M2AC = 600?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist3[bh.loc(500), bh.loc(600)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No time to cover here:\n",
    "boost has waaaaay more functions for which we don't have the time today. A small selection is listed below:\n",
    "\n",
    "- Continuous vs discrete axis\n",
    "- Variable bin width\n",
    "- Profile histograms\n",
    "- Density histograms\n",
    "- A lot more!\n",
    "\n",
    "More information can be found on the [GitHub page](https://github.com/scikit-hep/boost-histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
